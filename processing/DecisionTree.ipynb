{
 "metadata": {
  "name": "",
<<<<<<< Updated upstream
  "signature": "sha256:d6bf41ba9e2026bdbcc92aac6411aa0ca9cd5800dda78aef271994cdc78b5132"
=======
  "signature": "sha256:1306a26ef296a081c983f37ee780cf12e463fc3c55aa0dc5c8ef9e01aa2ec1fb"
>>>>>>> Stashed changes
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import sklearn\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn import tree\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.tree import export_graphviz\n",
<<<<<<< Updated upstream
      "from IPython.display import Image\n",
      "# from sklearn.naive_bayes import GaussianNB\n",
      "# from sklearn.metrics import precision_score\n",
      "# from sklearn.metrics import roc_auc_score\n",
      "# from sklearn.metrics import confusion_matrix\n",
      "# from sklearn import cross_validation\n",
      "import StringIO, pydot\n",
      "\n",
      "### reading csv file into list of lists, header and main body of the data\n",
=======
      "from IPython.display import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import StringIO, pydot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pydot",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-2adfd4d14ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mImportError\u001b[0m: No module named pydot"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
>>>>>>> Stashed changes
      "data = []\n",
      "c = 0\n",
      "with open('output.csv', 'rU') as f:  #opens PW file\n",
      "    reader = csv.reader(f)\n",
      "    for row in reader:\n",
      "    \tif c == 0:\n",
      "    \t\thead = row\n",
      "    \t\tc = 1\n",
      "    \telse:\n",
      "    \t\tdata.append(row)\n",
      "# print len(data)\n",
      "data = np.asarray(data)\n",
      "# print data_arr.shape\n",
      "\n",
      "numFeatures = len(head)\n",
<<<<<<< Updated upstream
      "numInstances = len(data)\n",
      "# print numFeatures, numInstances\n",
      "\n",
      "\n",
      "### delect the first attribute, 'id', attributes contains all the attributes need to fit the model\n",
      "attributes = data[:,3:]\n",
      "target = data[:,2]\n",
      "# print attributes.shape\n",
      "# print target.shape\n",
      "\n",
      "\n",
      "### randomly pick up training set and testing set\n",
      "Xtrain, Xtest, ytrain, ytest = train_test_split(attributes, target, train_size=666, test_size=333, random_state=42)\n",
      "\n",
      "### build up the tree and using split-testing data to test\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf = 1, max_depth=20)\n",
      "clf = clf.fit(Xtrain, ytrain)\n",
      "# myPredictions = clf.predict(Xtest)\n",
      "# correctClass = accuracy_score(ytest, myPredictions)\n",
      "# print correctClass\n",
      "\n",
      "dot_data = StringIO.StringIO()\n",
      "export_graphviz(clf, out_file=dot_data)\n",
      "print dot_data.getvalue()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "digraph Tree {\n",
        "0 [label=\"X[24] <= 0.5000\\nentropy = 0.706034897018\\nsamples = 666\", shape=\"box\"] ;\n",
        "1 [label=\"X[229] <= 0.5000\\nentropy = 0.450948426673\\nsamples = 392\", shape=\"box\"] ;\n",
        "0 -> 1 ;\n",
        "2 [label=\"X[37] <= 0.5000\\nentropy = 0.406970088377\\nsamples = 381\", shape=\"box\"] ;\n",
        "1 -> 2 ;\n",
        "3 [label=\"X[286] <= 0.5000\\nentropy = 0.342463772482\\nsamples = 329\", shape=\"box\"] ;\n",
        "2 -> 3 ;\n",
        "4 [label=\"X[493] <= 0.5000\\nentropy = 0.331305613058\\nsamples = 328\", shape=\"box\"] ;\n",
        "3 -> 4 ;\n",
        "5 [label=\"X[154] <= 0.5000\\nentropy = 0.319871971402\\nsamples = 327\", shape=\"box\"] ;\n",
        "4 -> 5 ;\n",
        "6 [label=\"X[68] <= 0.5000\\nentropy = 0.353359335021\\nsamples = 285\", shape=\"box\"] ;\n",
        "5 -> 6 ;\n",
        "7 [label=\"X[215] <= 0.5000\\nentropy = 0.322756958897\\nsamples = 272\", shape=\"box\"] ;\n",
        "6 -> 7 ;\n",
        "8 [label=\"X[25] <= 0.5000\\nentropy = 0.308704912446\\nsamples = 271\", shape=\"box\"] ;\n",
        "7 -> 8 ;\n",
        "9 [label=\"X[211] <= 0.5000\\nentropy = 0.342463772482\\nsamples = 235\", shape=\"box\"] ;\n",
        "8 -> 9 ;\n",
        "10 [label=\"X[74] <= 0.5000\\nentropy = 0.326765976488\\nsamples = 234\", shape=\"box\"] ;\n",
        "9 -> 10 ;\n",
        "11 [label=\"X[70] <= 0.5000\\nentropy = 0.310517246323\\nsamples = 233\", shape=\"box\"] ;\n",
        "10 -> 11 ;\n",
        "12 [label=\"X[5] <= 0.5000\\nentropy = 0.333808538889\\nsamples = 211\", shape=\"box\"] ;\n",
        "11 -> 12 ;\n",
        "13 [label=\"X[4] <= 0.5000\\nentropy = 0.352062972984\\nsamples = 196\", shape=\"box\"] ;\n",
        "12 -> 13 ;\n",
        "14 [label=\"X[2] <= 0.5000\\nentropy = 0.369786311075\\nsamples = 183\", shape=\"box\"] ;\n",
        "13 -> 14 ;\n",
        "15 [label=\"X[145] <= 0.5000\\nentropy = 0.383269164169\\nsamples = 174\", shape=\"box\"] ;\n",
        "14 -> 15 ;\n",
        "16 [label=\"X[28] <= 0.5000\\nentropy = 0.368115005428\\nsamples = 170\", shape=\"box\"] ;\n",
        "15 -> 16 ;\n",
        "17 [label=\"X[63] <= 0.5000\\nentropy = 0.379288487687\\nsamples = 163\", shape=\"box\"] ;\n",
        "16 -> 17 ;\n",
        "18 [label=\"X[16] <= 0.5000\\nentropy = 0.389484646593\\nsamples = 157\", shape=\"box\"] ;\n",
        "17 -> 18 ;\n",
        "19 [label=\"X[0] <= 0.5000\\nentropy = 0.398459274095\\nsamples = 152\", shape=\"box\"] ;\n",
        "18 -> 19 ;\n",
        "20 [label=\"entropy = 0.3691\\nsamples = 127\\nvalue = [ 118.    9.]\", shape=\"box\"] ;\n",
        "19 -> 20 ;\n",
        "21 [label=\"entropy = 0.5294\\nsamples = 25\\nvalue = [ 22.   3.]\", shape=\"box\"] ;\n",
        "19 -> 21 ;\n",
        "22 [label=\"entropy = 0.0000\\nsamples = 5\\nvalue = [ 5.  0.]\", shape=\"box\"] ;\n",
        "18 -> 22 ;\n",
        "23 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 6.  0.]\", shape=\"box\"] ;\n",
        "17 -> 23 ;\n",
        "24 [label=\"entropy = 0.0000\\nsamples = 7\\nvalue = [ 7.  0.]\", shape=\"box\"] ;\n",
        "16 -> 24 ;\n",
        "25 [label=\"X[90] <= 0.5000\\nentropy = 0.811278124459\\nsamples = 4\", shape=\"box\"] ;\n",
        "15 -> 25 ;\n",
        "26 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 2.  0.]\", shape=\"box\"] ;\n",
        "25 -> 26 ;\n",
        "27 [label=\"entropy = 1.0000\\nsamples = 2\\nvalue = [ 1.  1.]\", shape=\"box\"] ;\n",
        "25 -> 27 ;\n",
        "28 [label=\"entropy = 0.0000\\nsamples = 9\\nvalue = [ 9.  0.]\", shape=\"box\"] ;\n",
        "14 -> 28 ;\n",
        "29 [label=\"entropy = 0.0000\\nsamples = 13\\nvalue = [ 13.   0.]\", shape=\"box\"] ;\n",
        "13 -> 29 ;\n",
        "30 [label=\"entropy = 0.0000\\nsamples = 15\\nvalue = [ 15.   0.]\", shape=\"box\"] ;\n",
        "12 -> 30 ;\n",
        "31 [label=\"entropy = 0.0000\\nsamples = 22\\nvalue = [ 22.   0.]\", shape=\"box\"] ;\n",
        "11 -> 31 ;\n",
        "32 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "10 -> 32 ;\n",
        "33 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "9 -> 33 ;\n",
        "34 [label=\"entropy = 0.0000\\nsamples = 36\\nvalue = [ 36.   0.]\", shape=\"box\"] ;\n",
        "8 -> 34 ;\n",
        "35 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "7 -> 35 ;\n",
        "36 [label=\"X[205] <= 0.5000\\nentropy = 0.779349837292\\nsamples = 13\", shape=\"box\"] ;\n",
        "6 -> 36 ;\n",
        "37 [label=\"X[211] <= 0.5000\\nentropy = 0.439496986922\\nsamples = 11\", shape=\"box\"] ;\n",
        "36 -> 37 ;\n",
        "38 [label=\"entropy = 0.0000\\nsamples = 10\\nvalue = [ 10.   0.]\", shape=\"box\"] ;\n",
        "37 -> 38 ;\n",
        "39 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "37 -> 39 ;\n",
        "40 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "36 -> 40 ;\n",
        "41 [label=\"entropy = 0.0000\\nsamples = 42\\nvalue = [ 42.   0.]\", shape=\"box\"] ;\n",
        "5 -> 41 ;\n",
        "42 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "4 -> 42 ;\n",
        "43 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "3 -> 43 ;\n",
        "44 [label=\"X[170] <= 0.5000\\nentropy = 0.706274089188\\nsamples = 52\", shape=\"box\"] ;\n",
        "2 -> 44 ;\n",
        "45 [label=\"X[26] <= 0.5000\\nentropy = 0.634309554641\\nsamples = 50\", shape=\"box\"] ;\n",
        "44 -> 45 ;\n",
        "46 [label=\"X[383] <= 0.5000\\nentropy = 0.823811633312\\nsamples = 31\", shape=\"box\"] ;\n",
        "45 -> 46 ;\n",
        "47 [label=\"X[205] <= 0.5000\\nentropy = 0.735508581554\\nsamples = 29\", shape=\"box\"] ;\n",
        "46 -> 47 ;\n",
        "48 [label=\"X[53] <= 0.5000\\nentropy = 0.5435644432\\nsamples = 24\", shape=\"box\"] ;\n",
        "47 -> 48 ;\n",
        "49 [label=\"X[43] <= 0.5000\\nentropy = 0.286396957116\\nsamples = 20\", shape=\"box\"] ;\n",
        "48 -> 49 ;\n",
        "50 [label=\"X[48] <= 0.5000\\nentropy = 0.591672778582\\nsamples = 7\", shape=\"box\"] ;\n",
        "49 -> 50 ;\n",
        "51 [label=\"X[69] <= 0.5000\\nentropy = 0.811278124459\\nsamples = 4\", shape=\"box\"] ;\n",
        "50 -> 51 ;\n",
        "52 [label=\"X[145] <= 0.5000\\nentropy = 1.0\\nsamples = 2\", shape=\"box\"] ;\n",
        "51 -> 52 ;\n",
        "53 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "52 -> 53 ;\n",
        "54 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "52 -> 54 ;\n",
        "55 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 2.  0.]\", shape=\"box\"] ;\n",
        "51 -> 55 ;\n",
        "56 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 3.  0.]\", shape=\"box\"] ;\n",
        "50 -> 56 ;\n",
        "57 [label=\"entropy = 0.0000\\nsamples = 13\\nvalue = [ 13.   0.]\", shape=\"box\"] ;\n",
        "49 -> 57 ;\n",
        "58 [label=\"X[9] <= 0.5000\\nentropy = 1.0\\nsamples = 4\", shape=\"box\"] ;\n",
        "48 -> 58 ;\n",
        "59 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "58 -> 59 ;\n",
        "60 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 2.  0.]\", shape=\"box\"] ;\n",
        "58 -> 60 ;\n",
        "61 [label=\"X[143] <= 0.5000\\nentropy = 0.970950594455\\nsamples = 5\", shape=\"box\"] ;\n",
        "47 -> 61 ;\n",
        "62 [label=\"X[127] <= 0.5000\\nentropy = 0.918295834054\\nsamples = 3\", shape=\"box\"] ;\n",
        "61 -> 62 ;\n",
        "63 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 2.  0.]\", shape=\"box\"] ;\n",
        "62 -> 63 ;\n",
        "64 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "62 -> 64 ;\n",
        "65 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "61 -> 65 ;\n",
        "66 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "46 -> 66 ;\n",
        "67 [label=\"entropy = 0.0000\\nsamples = 19\\nvalue = [ 19.   0.]\", shape=\"box\"] ;\n",
        "45 -> 67 ;\n",
        "68 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "44 -> 68 ;\n",
        "69 [label=\"X[270] <= 0.5000\\nentropy = 0.994030211477\\nsamples = 11\", shape=\"box\"] ;\n",
        "1 -> 69 ;\n",
        "70 [label=\"X[43] <= 0.5000\\nentropy = 0.954434002925\\nsamples = 8\", shape=\"box\"] ;\n",
        "69 -> 70 ;\n",
        "71 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "70 -> 71 ;\n",
        "72 [label=\"X[106] <= 0.5000\\nentropy = 0.650022421648\\nsamples = 6\", shape=\"box\"] ;\n",
        "70 -> 72 ;\n",
        "73 [label=\"entropy = 0.0000\\nsamples = 5\\nvalue = [ 5.  0.]\", shape=\"box\"] ;\n",
        "72 -> 73 ;\n",
        "74 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "72 -> 74 ;\n",
        "75 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 0.  3.]\", shape=\"box\"] ;\n",
        "69 -> 75 ;\n",
        "76 [label=\"X[268] <= 0.5000\\nentropy = 0.917074481997\\nsamples = 274\", shape=\"box\"] ;\n",
        "0 -> 76 ;\n",
        "77 [label=\"X[416] <= 0.5000\\nentropy = 0.837536082179\\nsamples = 217\", shape=\"box\"] ;\n",
        "76 -> 77 ;\n",
        "78 [label=\"X[370] <= 0.5000\\nentropy = 0.807482548355\\nsamples = 210\", shape=\"box\"] ;\n",
        "77 -> 78 ;\n",
        "79 [label=\"X[371] <= 0.5000\\nentropy = 0.73260805402\\nsamples = 185\", shape=\"box\"] ;\n",
        "78 -> 79 ;\n",
        "80 [label=\"X[319] <= 0.5000\\nentropy = 0.652420517371\\nsamples = 161\", shape=\"box\"] ;\n",
        "79 -> 80 ;\n",
        "81 [label=\"X[355] <= 0.5000\\nentropy = 0.616966838452\\nsamples = 157\", shape=\"box\"] ;\n",
        "80 -> 81 ;\n",
        "82 [label=\"X[141] <= 0.5000\\nentropy = 0.577004250316\\nsamples = 153\", shape=\"box\"] ;\n",
        "81 -> 82 ;\n",
        "83 [label=\"X[116] <= 0.5000\\nentropy = 0.687644533458\\nsamples = 109\", shape=\"box\"] ;\n",
        "82 -> 83 ;\n",
        "84 [label=\"X[76] <= 0.5000\\nentropy = 0.570541142852\\nsamples = 89\", shape=\"box\"] ;\n",
        "83 -> 84 ;\n",
        "85 [label=\"X[11] <= 0.5000\\nentropy = 0.417864262446\\nsamples = 71\", shape=\"box\"] ;\n",
        "84 -> 85 ;\n",
        "86 [label=\"X[58] <= 0.5000\\nentropy = 0.619382194679\\nsamples = 39\", shape=\"box\"] ;\n",
        "85 -> 86 ;\n",
        "87 [label=\"X[64] <= 0.5000\\nentropy = 0.811278124459\\nsamples = 24\", shape=\"box\"] ;\n",
        "86 -> 87 ;\n",
        "88 [label=\"X[137] <= 0.5000\\nentropy = 0.684038435639\\nsamples = 22\", shape=\"box\"] ;\n",
        "87 -> 88 ;\n",
        "89 [label=\"X[323] <= 0.5000\\nentropy = 0.591672778582\\nsamples = 21\", shape=\"box\"] ;\n",
        "88 -> 89 ;\n",
        "90 [label=\"X[209] <= 0.5000\\nentropy = 0.468995593589\\nsamples = 20\", shape=\"box\"] ;\n",
        "89 -> 90 ;\n",
        "91 [label=\"X[255] <= 0.5000\\nentropy = 0.297472248919\\nsamples = 19\", shape=\"box\"] ;\n",
        "90 -> 91 ;\n",
        "92 [label=\"entropy = 0.0000\\nsamples = 18\\nvalue = [ 18.   0.]\", shape=\"box\"] ;\n",
        "91 -> 92 ;\n",
        "93 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "91 -> 93 ;\n",
        "94 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "90 -> 94 ;\n",
        "95 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "89 -> 95 ;\n",
        "96 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "88 -> 96 ;\n",
        "97 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "87 -> 97 ;\n",
        "98 [label=\"entropy = 0.0000\\nsamples = 15\\nvalue = [ 15.   0.]\", shape=\"box\"] ;\n",
        "86 -> 98 ;\n",
        "99 [label=\"entropy = 0.0000\\nsamples = 32\\nvalue = [ 32.   0.]\", shape=\"box\"] ;\n",
        "85 -> 99 ;\n",
        "100 [label=\"X[81] <= 0.5000\\nentropy = 0.918295834054\\nsamples = 18\", shape=\"box\"] ;\n",
        "84 -> 100 ;\n",
        "101 [label=\"X[71] <= 0.5000\\nentropy = 0.970950594455\\nsamples = 10\", shape=\"box\"] ;\n",
        "100 -> 101 ;\n",
        "102 [label=\"X[447] <= 0.5000\\nentropy = 0.591672778582\\nsamples = 7\", shape=\"box\"] ;\n",
        "101 -> 102 ;\n",
        "103 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 0.  6.]\", shape=\"box\"] ;\n",
        "102 -> 103 ;\n",
        "104 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "102 -> 104 ;\n",
        "105 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 3.  0.]\", shape=\"box\"] ;\n",
        "101 -> 105 ;\n",
        "106 [label=\"entropy = 0.0000\\nsamples = 8\\nvalue = [ 8.  0.]\", shape=\"box\"] ;\n",
        "100 -> 106 ;\n",
        "107 [label=\"X[93] <= 0.5000\\nentropy = 0.970950594455\\nsamples = 20\", shape=\"box\"] ;\n",
        "83 -> 107 ;\n",
        "108 [label=\"X[25] <= 0.5000\\nentropy = 0.5435644432\\nsamples = 8\", shape=\"box\"] ;\n",
        "107 -> 108 ;\n",
        "109 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "108 -> 109 ;\n",
        "110 [label=\"entropy = 0.0000\\nsamples = 7\\nvalue = [ 0.  7.]\", shape=\"box\"] ;\n",
        "108 -> 110 ;\n",
        "111 [label=\"X[30] <= 0.5000\\nentropy = 0.413816850304\\nsamples = 12\", shape=\"box\"] ;\n",
        "107 -> 111 ;\n",
        "112 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "111 -> 112 ;\n",
        "113 [label=\"entropy = 0.0000\\nsamples = 11\\nvalue = [ 11.   0.]\", shape=\"box\"] ;\n",
        "111 -> 113 ;\n",
        "114 [label=\"X[102] <= 0.5000\\nentropy = 0.156491062906\\nsamples = 44\", shape=\"box\"] ;\n",
        "82 -> 114 ;\n",
        "115 [label=\"entropy = 0.0000\\nsamples = 43\\nvalue = [ 43.   0.]\", shape=\"box\"] ;\n",
        "114 -> 115 ;\n",
        "116 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 0.  1.]\", shape=\"box\"] ;\n",
        "114 -> 116 ;\n",
        "117 [label=\"X[161] <= 0.5000\\nentropy = 0.811278124459\\nsamples = 4\", shape=\"box\"] ;\n",
        "81 -> 117 ;\n",
        "118 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 0.  3.]\", shape=\"box\"] ;\n",
        "117 -> 118 ;\n",
        "119 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "117 -> 119 ;\n",
        "120 [label=\"X[85] <= 0.5000\\nentropy = 0.811278124459\\nsamples = 4\", shape=\"box\"] ;\n",
        "80 -> 120 ;\n",
        "121 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "120 -> 121 ;\n",
        "122 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 0.  3.]\", shape=\"box\"] ;\n",
        "120 -> 122 ;\n",
        "123 [label=\"X[304] <= 0.5000\\nentropy = 0.994984828186\\nsamples = 24\", shape=\"box\"] ;\n",
        "79 -> 123 ;\n",
        "124 [label=\"X[434] <= 0.5000\\nentropy = 0.934068055375\\nsamples = 20\", shape=\"box\"] ;\n",
        "123 -> 124 ;\n",
        "125 [label=\"X[123] <= 0.5000\\nentropy = 0.852405178649\\nsamples = 18\", shape=\"box\"] ;\n",
        "124 -> 125 ;\n",
        "126 [label=\"X[463] <= 0.5000\\nentropy = 0.994030211477\\nsamples = 11\", shape=\"box\"] ;\n",
        "125 -> 126 ;\n",
        "127 [label=\"X[332] <= 0.5000\\nentropy = 0.811278124459\\nsamples = 8\", shape=\"box\"] ;\n",
        "126 -> 127 ;\n",
        "128 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 6.  0.]\", shape=\"box\"] ;\n",
        "127 -> 128 ;\n",
        "129 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "127 -> 129 ;\n",
        "130 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 0.  3.]\", shape=\"box\"] ;\n",
        "126 -> 130 ;\n",
        "131 [label=\"entropy = 0.0000\\nsamples = 7\\nvalue = [ 7.  0.]\", shape=\"box\"] ;\n",
        "125 -> 131 ;\n",
        "132 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "124 -> 132 ;\n",
        "133 [label=\"entropy = 0.0000\\nsamples = 4\\nvalue = [ 0.  4.]\", shape=\"box\"] ;\n",
        "123 -> 133 ;\n",
        "134 [label=\"X[298] <= 0.5000\\nentropy = 0.989587521222\\nsamples = 25\", shape=\"box\"] ;\n",
        "78 -> 134 ;\n",
        "135 [label=\"X[158] <= 0.5000\\nentropy = 0.863120568567\\nsamples = 14\", shape=\"box\"] ;\n",
        "134 -> 135 ;\n",
        "136 [label=\"X[86] <= 0.5000\\nentropy = 0.650022421648\\nsamples = 12\", shape=\"box\"] ;\n",
        "135 -> 136 ;\n",
        "137 [label=\"X[30] <= 0.5000\\nentropy = 0.918295834054\\nsamples = 3\", shape=\"box\"] ;\n",
        "136 -> 137 ;\n",
        "138 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "137 -> 138 ;\n",
        "139 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "137 -> 139 ;\n",
        "140 [label=\"entropy = 0.0000\\nsamples = 9\\nvalue = [ 9.  0.]\", shape=\"box\"] ;\n",
        "136 -> 140 ;\n",
        "141 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "135 -> 141 ;\n",
        "142 [label=\"X[428] <= 0.5000\\nentropy = 0.439496986922\\nsamples = 11\", shape=\"box\"] ;\n",
        "134 -> 142 ;\n",
        "143 [label=\"entropy = 0.0000\\nsamples = 10\\nvalue = [  0.  10.]\", shape=\"box\"] ;\n",
        "142 -> 143 ;\n",
        "144 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "142 -> 144 ;\n",
        "145 [label=\"X[488] <= 0.5000\\nentropy = 0.591672778582\\nsamples = 7\", shape=\"box\"] ;\n",
        "77 -> 145 ;\n",
        "146 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 0.  6.]\", shape=\"box\"] ;\n",
        "145 -> 146 ;\n",
        "147 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "145 -> 147 ;\n",
        "148 [label=\"X[327] <= 0.5000\\nentropy = 0.981940786864\\nsamples = 57\", shape=\"box\"] ;\n",
        "76 -> 148 ;\n",
        "149 [label=\"X[376] <= 0.5000\\nentropy = 0.956155023684\\nsamples = 53\", shape=\"box\"] ;\n",
        "148 -> 149 ;\n",
        "150 [label=\"X[249] <= 0.5000\\nentropy = 0.998195879043\\nsamples = 40\", shape=\"box\"] ;\n",
        "149 -> 150 ;\n",
        "151 [label=\"X[62] <= 0.5000\\nentropy = 0.989992791558\\nsamples = 34\", shape=\"box\"] ;\n",
        "150 -> 151 ;\n",
        "152 [label=\"X[152] <= 0.5000\\nentropy = 0.996316519559\\nsamples = 28\", shape=\"box\"] ;\n",
        "151 -> 152 ;\n",
        "153 [label=\"X[310] <= 0.5000\\nentropy = 0.954434002925\\nsamples = 24\", shape=\"box\"] ;\n",
        "152 -> 153 ;\n",
        "154 [label=\"X[42] <= 0.5000\\nentropy = 0.863120568567\\nsamples = 21\", shape=\"box\"] ;\n",
        "153 -> 154 ;\n",
        "155 [label=\"X[208] <= 0.5000\\nentropy = 0.985228136034\\nsamples = 14\", shape=\"box\"] ;\n",
        "154 -> 155 ;\n",
        "156 [label=\"X[37] <= 0.5000\\nentropy = 0.845350936622\\nsamples = 11\", shape=\"box\"] ;\n",
        "155 -> 156 ;\n",
        "157 [label=\"X[28] <= 0.5000\\nentropy = 0.970950594455\\nsamples = 5\", shape=\"box\"] ;\n",
        "156 -> 157 ;\n",
        "158 [label=\"entropy = 0.0000\\nsamples = 2\\nvalue = [ 0.  2.]\", shape=\"box\"] ;\n",
        "157 -> 158 ;\n",
        "159 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 3.  0.]\", shape=\"box\"] ;\n",
        "157 -> 159 ;\n",
        "160 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 0.  6.]\", shape=\"box\"] ;\n",
        "156 -> 160 ;\n",
        "161 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 3.  0.]\", shape=\"box\"] ;\n",
        "155 -> 161 ;\n",
        "162 [label=\"entropy = 0.0000\\nsamples = 7\\nvalue = [ 0.  7.]\", shape=\"box\"] ;\n",
        "154 -> 162 ;\n",
        "163 [label=\"entropy = 0.0000\\nsamples = 3\\nvalue = [ 3.  0.]\", shape=\"box\"] ;\n",
        "153 -> 163 ;\n",
        "164 [label=\"entropy = 0.0000\\nsamples = 4\\nvalue = [ 4.  0.]\", shape=\"box\"] ;\n",
        "152 -> 164 ;\n",
        "165 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 6.  0.]\", shape=\"box\"] ;\n",
        "151 -> 165 ;\n",
        "166 [label=\"entropy = 0.0000\\nsamples = 6\\nvalue = [ 0.  6.]\", shape=\"box\"] ;\n",
        "150 -> 166 ;\n",
        "167 [label=\"X[476] <= 0.5000\\nentropy = 0.391243563629\\nsamples = 13\", shape=\"box\"] ;\n",
        "149 -> 167 ;\n",
        "168 [label=\"entropy = 0.0000\\nsamples = 12\\nvalue = [  0.  12.]\", shape=\"box\"] ;\n",
        "167 -> 168 ;\n",
        "169 [label=\"entropy = 0.0000\\nsamples = 1\\nvalue = [ 1.  0.]\", shape=\"box\"] ;\n",
        "167 -> 169 ;\n",
        "170 [label=\"entropy = 0.0000\\nsamples = 4\\nvalue = [ 4.  0.]\", shape=\"box\"] ;\n",
        "148 -> 170 ;\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 1
=======
      "numInstances = len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "attributes = data[:,1:-1]\n",
      "target = data[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtrain, Xtest, ytrain, ytest = train_test_split(attributes, target, train_size=666, test_size=333, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf = 1, max_depth=100)\n",
      "clf = clf.fit(Xtrain, ytrain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
>>>>>>> Stashed changes
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def viz(decision_tree, feature_names=None):\n",
      "  from warnings import warn\n",
      " \n",
      "  js = \"\"\n",
      " \n",
      "  def node_to_str(tree, node_id, criterion):\n",
      "    if not isinstance(criterion, sklearn.tree.tree.six.string_types):\n",
      "      criterion = \"impurity\"\n",
      " \n",
      "    value = tree.value[node_id]\n",
      "    if tree.n_outputs == 1:\n",
      "      value = value[0, :]\n",
      " \n",
      "    if tree.children_left[node_id] == sklearn.tree._tree.TREE_LEAF:\n",
      "      return '\"id\": \"%s\", \"criterion\": \"%s\", \"impurity\": \"%s\", \"samples\": \"%s\", \"value\": \"%s\"' \\\n",
      "             % (node_id, \n",
      "                criterion,\n",
      "                tree.impurity[node_id],\n",
      "                tree.n_node_samples[node_id],\n",
      "                value)\n",
      "    else:\n",
      "      if feature_names is not None:\n",
      "        feature = feature_names[tree.feature[node_id]]\n",
      "      else:\n",
      "        feature = tree.feature[node_id]\n",
      " \n",
      "      return '\"id\": \"%s\", \"rule\": \"%s <= %.4f\", \"%s\": \"%s\", \"samples\": \"%s\"' \\\n",
      "             % (node_id, \n",
      "                feature,\n",
      "                tree.threshold[node_id],\n",
      "                criterion,\n",
      "                tree.impurity[node_id],\n",
      "                tree.n_node_samples[node_id])\n",
      " \n",
      "  def recurse(tree, node_id, criterion, parent=None, depth=0):\n",
      "    tabs = \"  \" * depth\n",
      "    js = \"\"\n",
      " \n",
      "    left_child = tree.children_left[node_id]\n",
      "    right_child = tree.children_right[node_id]\n",
      " \n",
      "    js = js + \"\\n\" + \\\n",
      "         tabs + \"{\\n\" + \\\n",
      "         tabs + \"  \" + node_to_str(tree, node_id, criterion)\n",
      " \n",
      "    if left_child != sklearn.tree._tree.TREE_LEAF:\n",
      "      js = js + \",\\n\" + \\\n",
      "           tabs + '  \"left\": ' + \\\n",
      "           recurse(tree, \\\n",
      "                   left_child, \\\n",
      "                   criterion=criterion, \\\n",
      "                   parent=node_id, \\\n",
      "                   depth=depth + 1) + \",\\n\" + \\\n",
      "           tabs + '  \"right\": ' + \\\n",
      "           recurse(tree, \\\n",
      "                   right_child, \\\n",
      "                   criterion=criterion, \\\n",
      "                   parent=node_id,\n",
      "                   depth=depth + 1)\n",
      " \n",
      "    js = js + tabs + \"\\n\" + \\\n",
      "         tabs + \"}\"\n",
      " \n",
      "    return js\n",
      " \n",
      "  if isinstance(decision_tree, sklearn.tree.tree.Tree):\n",
      "    js = js + recurse(decision_tree, 0, criterion=\"impurity\")\n",
      "  else:\n",
      "    js = js + recurse(decision_tree.tree_, 0, criterion=decision_tree.criterion)\n",
      " \n",
      "  return js"
     ],
     "language": "python",
     "metadata": {},
<<<<<<< Updated upstream
     "outputs": [],
     "prompt_number": 4
=======
     "outputs": []
>>>>>>> Stashed changes
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print viz(clf, feature_names=head)"
     ],
     "language": "python",
     "metadata": {},
<<<<<<< Updated upstream
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{\n",
        "  \"id\": \"0\", \"rule\": \"diagnosis__HIERARCHY_2.16 <= 0.5000\", \"entropy\": \"0.706034897018\", \"samples\": \"666\",\n",
        "  \"left\": \n",
        "  {\n",
        "    \"id\": \"1\", \"rule\": \"diagnosis__2948 <= 0.5000\", \"entropy\": \"0.450948426673\", \"samples\": \"392\",\n",
        "    \"left\": \n",
        "    {\n",
        "      \"id\": \"2\", \"rule\": \"diagnosis__HIERARCHY_7.1 <= 0.5000\", \"entropy\": \"0.406970088377\", \"samples\": \"381\",\n",
        "      \"left\": \n",
        "      {\n",
        "        \"id\": \"3\", \"rule\": \"diagnosis__HIERARCHY_6.5.2 <= 0.5000\", \"entropy\": \"0.342463772482\", \"samples\": \"329\",\n",
        "        \"left\": \n",
        "        {\n",
        "          \"id\": \"4\", \"rule\": \"diagnosis__HIERARCHY_7.5.2 <= 0.5000\", \"entropy\": \"0.331305613058\", \"samples\": \"328\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"5\", \"rule\": \"diagnosis__42731 <= 0.5000\", \"entropy\": \"0.319871971402\", \"samples\": \"327\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"6\", \"rule\": \"diagnosis__HIERARCHY_7.2.1.2 <= 0.5000\", \"entropy\": \"0.353359335021\", \"samples\": \"285\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"7\", \"rule\": \"diagnosis__7395 <= 0.5000\", \"entropy\": \"0.322756958897\", \"samples\": \"272\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"8\", \"rule\": \"diagnosis__HIERARCHY_4 <= 0.5000\", \"entropy\": \"0.308704912446\", \"samples\": \"271\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"9\", \"rule\": \"diagnosis__HIERARCHY_7.2.5 <= 0.5000\", \"entropy\": \"0.342463772482\", \"samples\": \"235\",\n",
        "                    \"left\": \n",
        "                    {\n",
        "                      \"id\": \"10\", \"rule\": \"diagnosis__HIERARCHY_6.7.4 <= 0.5000\", \"entropy\": \"0.326765976488\", \"samples\": \"234\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"11\", \"rule\": \"diagnosis__HIERARCHY_12 <= 0.5000\", \"entropy\": \"0.310517246323\", \"samples\": \"233\",\n",
        "                        \"left\": \n",
        "                        {\n",
        "                          \"id\": \"12\", \"rule\": \"info__age_40_50 <= 0.5000\", \"entropy\": \"0.333808538889\", \"samples\": \"211\",\n",
        "                          \"left\": \n",
        "                          {\n",
        "                            \"id\": \"13\", \"rule\": \"info__age_80_90 <= 0.5000\", \"entropy\": \"0.352062972984\", \"samples\": \"196\",\n",
        "                            \"left\": \n",
        "                            {\n",
        "                              \"id\": \"14\", \"rule\": \"outcome <= 0.5000\", \"entropy\": \"0.369786311075\", \"samples\": \"183\",\n",
        "                              \"left\": \n",
        "                              {\n",
        "                                \"id\": \"15\", \"rule\": \"diagnosis__HIERARCHY_12.2 <= 0.5000\", \"entropy\": \"0.383269164169\", \"samples\": \"174\",\n",
        "                                \"left\": \n",
        "                                {\n",
        "                                  \"id\": \"16\", \"rule\": \"diagnosis__HIERARCHY_7 <= 0.5000\", \"entropy\": \"0.368115005428\", \"samples\": \"170\",\n",
        "                                  \"left\": \n",
        "                                  {\n",
        "                                    \"id\": \"17\", \"rule\": \"diagnosis__HIERARCHY_12.3.1 <= 0.5000\", \"entropy\": \"0.379288487687\", \"samples\": \"163\",\n",
        "                                    \"left\": \n",
        "                                    {\n",
        "                                      \"id\": \"18\", \"rule\": \"diagnosis__HIERARCHY_9.6.4.1 <= 0.5000\", \"entropy\": \"0.389484646593\", \"samples\": \"157\",\n",
        "                                      \"left\": \n",
        "                                      {\n",
        "                                        \"id\": \"19\", \"rule\": \"id <= 0.5000\", \"entropy\": \"0.398459274095\", \"samples\": \"152\",\n",
        "                                        \"left\": \n",
        "                                        {\n",
        "                                          \"id\": \"20\", \"criterion\": \"entropy\", \"impurity\": \"0.369147640806\", \"samples\": \"127\", \"value\": \"[ 118.    9.]\"                                        \n",
        "                                        },\n",
        "                                        \"right\": \n",
        "                                        {\n",
        "                                          \"id\": \"21\", \"criterion\": \"entropy\", \"impurity\": \"0.529360865287\", \"samples\": \"25\", \"value\": \"[ 22.   3.]\"                                        \n",
        "                                        }                                      \n",
        "                                      },\n",
        "                                      \"right\": \n",
        "                                      {\n",
        "                                        \"id\": \"22\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"5\", \"value\": \"[ 5.  0.]\"                                      \n",
        "                                      }                                    \n",
        "                                    },\n",
        "                                    \"right\": \n",
        "                                    {\n",
        "                                      \"id\": \"23\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 6.  0.]\"                                    \n",
        "                                    }                                  \n",
        "                                  },\n",
        "                                  \"right\": \n",
        "                                  {\n",
        "                                    \"id\": \"24\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"7\", \"value\": \"[ 7.  0.]\"                                  \n",
        "                                  }                                \n",
        "                                },\n",
        "                                \"right\": \n",
        "                                {\n",
        "                                  \"id\": \"25\", \"rule\": \"diagnosis__4011 <= 0.5000\", \"entropy\": \"0.811278124459\", \"samples\": \"4\",\n",
        "                                  \"left\": \n",
        "                                  {\n",
        "                                    \"id\": \"26\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 2.  0.]\"                                  \n",
        "                                  },\n",
        "                                  \"right\": \n",
        "                                  {\n",
        "                                    \"id\": \"27\", \"criterion\": \"entropy\", \"impurity\": \"1.0\", \"samples\": \"2\", \"value\": \"[ 1.  1.]\"                                  \n",
        "                                  }                                \n",
        "                                }                              \n",
        "                              },\n",
        "                              \"right\": \n",
        "                              {\n",
        "                                \"id\": \"28\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"9\", \"value\": \"[ 9.  0.]\"                              \n",
        "                              }                            \n",
        "                            },\n",
        "                            \"right\": \n",
        "                            {\n",
        "                              \"id\": \"29\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"13\", \"value\": \"[ 13.   0.]\"                            \n",
        "                            }                          \n",
        "                          },\n",
        "                          \"right\": \n",
        "                          {\n",
        "                            \"id\": \"30\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"15\", \"value\": \"[ 15.   0.]\"                          \n",
        "                          }                        \n",
        "                        },\n",
        "                        \"right\": \n",
        "                        {\n",
        "                          \"id\": \"31\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"22\", \"value\": \"[ 22.   0.]\"                        \n",
        "                        }                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"32\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                      \n",
        "                      }                    \n",
        "                    },\n",
        "                    \"right\": \n",
        "                    {\n",
        "                      \"id\": \"33\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                    \n",
        "                    }                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"34\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"36\", \"value\": \"[ 36.   0.]\"                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"35\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                \n",
        "                }              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"36\", \"rule\": \"diagnosis__HIERARCHY_4.1.3.3 <= 0.5000\", \"entropy\": \"0.779349837292\", \"samples\": \"13\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"37\", \"rule\": \"diagnosis__HIERARCHY_7.2.5 <= 0.5000\", \"entropy\": \"0.439496986922\", \"samples\": \"11\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"38\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"10\", \"value\": \"[ 10.   0.]\"                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"39\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"40\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                \n",
        "                }              \n",
        "              }            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"41\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"42\", \"value\": \"[ 42.   0.]\"            \n",
        "            }          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"42\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"          \n",
        "          }        \n",
        "        },\n",
        "        \"right\": \n",
        "        {\n",
        "          \"id\": \"43\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"        \n",
        "        }      \n",
        "      },\n",
        "      \"right\": \n",
        "      {\n",
        "        \"id\": \"44\", \"rule\": \"diagnosis__HIERARCHY_6.7.2.3 <= 0.5000\", \"entropy\": \"0.706274089188\", \"samples\": \"52\",\n",
        "        \"left\": \n",
        "        {\n",
        "          \"id\": \"45\", \"rule\": \"diagnosis__HIERARCHY_9.12.3 <= 0.5000\", \"entropy\": \"0.634309554641\", \"samples\": \"50\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"46\", \"rule\": \"diagnosis__5849 <= 0.5000\", \"entropy\": \"0.823811633312\", \"samples\": \"31\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"47\", \"rule\": \"diagnosis__HIERARCHY_4.1.3.3 <= 0.5000\", \"entropy\": \"0.735508581554\", \"samples\": \"29\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"48\", \"rule\": \"diagnosis__412 <= 0.5000\", \"entropy\": \"0.5435644432\", \"samples\": \"24\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"49\", \"rule\": \"diagnosis__HIERARCHY_7.2.9.5 <= 0.5000\", \"entropy\": \"0.286396957116\", \"samples\": \"20\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"50\", \"rule\": \"diagnosis__V5861 <= 0.5000\", \"entropy\": \"0.591672778582\", \"samples\": \"7\",\n",
        "                    \"left\": \n",
        "                    {\n",
        "                      \"id\": \"51\", \"rule\": \"diagnosis__HIERARCHY_17.1 <= 0.5000\", \"entropy\": \"0.811278124459\", \"samples\": \"4\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"52\", \"rule\": \"diagnosis__HIERARCHY_12.2 <= 0.5000\", \"entropy\": \"1.0\", \"samples\": \"2\",\n",
        "                        \"left\": \n",
        "                        {\n",
        "                          \"id\": \"53\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                        \n",
        "                        },\n",
        "                        \"right\": \n",
        "                        {\n",
        "                          \"id\": \"54\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"                        \n",
        "                        }                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"55\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 2.  0.]\"                      \n",
        "                      }                    \n",
        "                    },\n",
        "                    \"right\": \n",
        "                    {\n",
        "                      \"id\": \"56\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 3.  0.]\"                    \n",
        "                    }                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"57\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"13\", \"value\": \"[ 13.   0.]\"                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"58\", \"rule\": \"info__age_100_110 <= 0.5000\", \"entropy\": \"1.0\", \"samples\": \"4\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"59\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"60\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 2.  0.]\"                  \n",
        "                  }                \n",
        "                }              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"61\", \"rule\": \"diagnosis__HIERARCHY_13.2.2.1 <= 0.5000\", \"entropy\": \"0.970950594455\", \"samples\": \"5\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"62\", \"rule\": \"diagnosis__HIERARCHY_6.8.1.2 <= 0.5000\", \"entropy\": \"0.918295834054\", \"samples\": \"3\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"63\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 2.  0.]\"                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"64\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"65\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                \n",
        "                }              \n",
        "              }            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"66\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"            \n",
        "            }          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"67\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"19\", \"value\": \"[ 19.   0.]\"          \n",
        "          }        \n",
        "        },\n",
        "        \"right\": \n",
        "        {\n",
        "          \"id\": \"68\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"        \n",
        "        }      \n",
        "      }    \n",
        "    },\n",
        "    \"right\": \n",
        "    {\n",
        "      \"id\": \"69\", \"rule\": \"diagnosis__HIERARCHY_7.2.11.1 <= 0.5000\", \"entropy\": \"0.994030211477\", \"samples\": \"11\",\n",
        "      \"left\": \n",
        "      {\n",
        "        \"id\": \"70\", \"rule\": \"diagnosis__HIERARCHY_7.2.9.5 <= 0.5000\", \"entropy\": \"0.954434002925\", \"samples\": \"8\",\n",
        "        \"left\": \n",
        "        {\n",
        "          \"id\": \"71\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"        \n",
        "        },\n",
        "        \"right\": \n",
        "        {\n",
        "          \"id\": \"72\", \"rule\": \"diagnosis__78841 <= 0.5000\", \"entropy\": \"0.650022421648\", \"samples\": \"6\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"73\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"5\", \"value\": \"[ 5.  0.]\"          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"74\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"          \n",
        "          }        \n",
        "        }      \n",
        "      },\n",
        "      \"right\": \n",
        "      {\n",
        "        \"id\": \"75\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 0.  3.]\"      \n",
        "      }    \n",
        "    }  \n",
        "  },\n",
        "  \"right\": \n",
        "  {\n",
        "    \"id\": \"76\", \"rule\": \"diagnosis__HIERARCHY_3.8.4 <= 0.5000\", \"entropy\": \"0.917074481997\", \"samples\": \"274\",\n",
        "    \"left\": \n",
        "    {\n",
        "      \"id\": \"77\", \"rule\": \"diagnosis__HIERARCHY_8.1.5.2 <= 0.5000\", \"entropy\": \"0.837536082179\", \"samples\": \"217\",\n",
        "      \"left\": \n",
        "      {\n",
        "        \"id\": \"78\", \"rule\": \"diagnosis__HIERARCHY_3.7 <= 0.5000\", \"entropy\": \"0.807482548355\", \"samples\": \"210\",\n",
        "        \"left\": \n",
        "        {\n",
        "          \"id\": \"79\", \"rule\": \"diagnosis__79029 <= 0.5000\", \"entropy\": \"0.73260805402\", \"samples\": \"185\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"80\", \"rule\": \"diagnosis__7823 <= 0.5000\", \"entropy\": \"0.652420517371\", \"samples\": \"161\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"81\", \"rule\": \"diagnosis__HIERARCHY_10.1.2 <= 0.5000\", \"entropy\": \"0.616966838452\", \"samples\": \"157\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"82\", \"rule\": \"diagnosis__HIERARCHY_2.5 <= 0.5000\", \"entropy\": \"0.577004250316\", \"samples\": \"153\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"83\", \"rule\": \"diagnosis__HIERARCHY_8.5.1 <= 0.5000\", \"entropy\": \"0.687644533458\", \"samples\": \"109\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"84\", \"rule\": \"diagnosis__HIERARCHY_13.3.2 <= 0.5000\", \"entropy\": \"0.570541142852\", \"samples\": \"89\",\n",
        "                    \"left\": \n",
        "                    {\n",
        "                      \"id\": \"85\", \"rule\": \"diagnosis__HIERARCHY_9.6.4 <= 0.5000\", \"entropy\": \"0.417864262446\", \"samples\": \"71\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"86\", \"rule\": \"diagnosis__41401 <= 0.5000\", \"entropy\": \"0.619382194679\", \"samples\": \"39\",\n",
        "                        \"left\": \n",
        "                        {\n",
        "                          \"id\": \"87\", \"rule\": \"diagnosis__HIERARCHY_12.3 <= 0.5000\", \"entropy\": \"0.811278124459\", \"samples\": \"24\",\n",
        "                          \"left\": \n",
        "                          {\n",
        "                            \"id\": \"88\", \"rule\": \"diagnosis__HIERARCHY_6.8.2 <= 0.5000\", \"entropy\": \"0.684038435639\", \"samples\": \"22\",\n",
        "                            \"left\": \n",
        "                            {\n",
        "                              \"id\": \"89\", \"rule\": \"diagnosis__HIERARCHY_10.1.4.3 <= 0.5000\", \"entropy\": \"0.591672778582\", \"samples\": \"21\",\n",
        "                              \"left\": \n",
        "                              {\n",
        "                                \"id\": \"90\", \"rule\": \"diagnosis__HIERARCHY_17.1.1 <= 0.5000\", \"entropy\": \"0.468995593589\", \"samples\": \"20\",\n",
        "                                \"left\": \n",
        "                                {\n",
        "                                  \"id\": \"91\", \"rule\": \"diagnosis__HIERARCHY_10.1.4.1 <= 0.5000\", \"entropy\": \"0.297472248919\", \"samples\": \"19\",\n",
        "                                  \"left\": \n",
        "                                  {\n",
        "                                    \"id\": \"92\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"18\", \"value\": \"[ 18.   0.]\"                                  \n",
        "                                  },\n",
        "                                  \"right\": \n",
        "                                  {\n",
        "                                    \"id\": \"93\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                                  \n",
        "                                  }                                \n",
        "                                },\n",
        "                                \"right\": \n",
        "                                {\n",
        "                                  \"id\": \"94\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                                \n",
        "                                }                              \n",
        "                              },\n",
        "                              \"right\": \n",
        "                              {\n",
        "                                \"id\": \"95\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                              \n",
        "                              }                            \n",
        "                            },\n",
        "                            \"right\": \n",
        "                            {\n",
        "                              \"id\": \"96\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                            \n",
        "                            }                          \n",
        "                          },\n",
        "                          \"right\": \n",
        "                          {\n",
        "                            \"id\": \"97\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                          \n",
        "                          }                        \n",
        "                        },\n",
        "                        \"right\": \n",
        "                        {\n",
        "                          \"id\": \"98\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"15\", \"value\": \"[ 15.   0.]\"                        \n",
        "                        }                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"99\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"32\", \"value\": \"[ 32.   0.]\"                      \n",
        "                      }                    \n",
        "                    },\n",
        "                    \"right\": \n",
        "                    {\n",
        "                      \"id\": \"100\", \"rule\": \"diagnosis__HIERARCHY_13.4 <= 0.5000\", \"entropy\": \"0.918295834054\", \"samples\": \"18\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"101\", \"rule\": \"diagnosis__HIERARCHY_6.7 <= 0.5000\", \"entropy\": \"0.970950594455\", \"samples\": \"10\",\n",
        "                        \"left\": \n",
        "                        {\n",
        "                          \"id\": \"102\", \"rule\": \"diagnosis__HIERARCHY_9.4.4 <= 0.5000\", \"entropy\": \"0.591672778582\", \"samples\": \"7\",\n",
        "                          \"left\": \n",
        "                          {\n",
        "                            \"id\": \"103\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 0.  6.]\"                          \n",
        "                          },\n",
        "                          \"right\": \n",
        "                          {\n",
        "                            \"id\": \"104\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"                          \n",
        "                          }                        \n",
        "                        },\n",
        "                        \"right\": \n",
        "                        {\n",
        "                          \"id\": \"105\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 3.  0.]\"                        \n",
        "                        }                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"106\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"8\", \"value\": \"[ 8.  0.]\"                      \n",
        "                      }                    \n",
        "                    }                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"107\", \"rule\": \"diagnosis__HIERARCHY_18 <= 0.5000\", \"entropy\": \"0.970950594455\", \"samples\": \"20\",\n",
        "                    \"left\": \n",
        "                    {\n",
        "                      \"id\": \"108\", \"rule\": \"diagnosis__HIERARCHY_4 <= 0.5000\", \"entropy\": \"0.5435644432\", \"samples\": \"8\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"109\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"110\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"7\", \"value\": \"[ 0.  7.]\"                      \n",
        "                      }                    \n",
        "                    },\n",
        "                    \"right\": \n",
        "                    {\n",
        "                      \"id\": \"111\", \"rule\": \"diagnosis__HIERARCHY_8.1.5.4 <= 0.5000\", \"entropy\": \"0.413816850304\", \"samples\": \"12\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"112\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"113\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"11\", \"value\": \"[ 11.   0.]\"                      \n",
        "                      }                    \n",
        "                    }                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"114\", \"rule\": \"diagnosis__72887 <= 0.5000\", \"entropy\": \"0.156491062906\", \"samples\": \"44\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"115\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"43\", \"value\": \"[ 43.   0.]\"                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"116\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 0.  1.]\"                  \n",
        "                  }                \n",
        "                }              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"117\", \"rule\": \"diagnosis__HIERARCHY_3.5 <= 0.5000\", \"entropy\": \"0.811278124459\", \"samples\": \"4\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"118\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 0.  3.]\"                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"119\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"                \n",
        "                }              \n",
        "              }            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"120\", \"rule\": \"diagnosis__7231 <= 0.5000\", \"entropy\": \"0.811278124459\", \"samples\": \"4\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"121\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"122\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 0.  3.]\"              \n",
        "              }            \n",
        "            }          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"123\", \"rule\": \"diagnosis__HIERARCHY_1.1 <= 0.5000\", \"entropy\": \"0.994984828186\", \"samples\": \"24\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"124\", \"rule\": \"diagnosis__HIERARCHY_7.2.6 <= 0.5000\", \"entropy\": \"0.934068055375\", \"samples\": \"20\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"125\", \"rule\": \"diagnosis__HIERARCHY_8.2 <= 0.5000\", \"entropy\": \"0.852405178649\", \"samples\": \"18\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"126\", \"rule\": \"diagnosis__4293 <= 0.5000\", \"entropy\": \"0.994030211477\", \"samples\": \"11\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"127\", \"rule\": \"diagnosis__HIERARCHY_6.7.5 <= 0.5000\", \"entropy\": \"0.811278124459\", \"samples\": \"8\",\n",
        "                    \"left\": \n",
        "                    {\n",
        "                      \"id\": \"128\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 6.  0.]\"                    \n",
        "                    },\n",
        "                    \"right\": \n",
        "                    {\n",
        "                      \"id\": \"129\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                    \n",
        "                    }                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"130\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 0.  3.]\"                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"131\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"7\", \"value\": \"[ 7.  0.]\"                \n",
        "                }              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"132\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"              \n",
        "              }            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"133\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"4\", \"value\": \"[ 0.  4.]\"            \n",
        "            }          \n",
        "          }        \n",
        "        },\n",
        "        \"right\": \n",
        "        {\n",
        "          \"id\": \"134\", \"rule\": \"diagnosis__V0481 <= 0.5000\", \"entropy\": \"0.989587521222\", \"samples\": \"25\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"135\", \"rule\": \"diagnosis__HIERARCHY_16 <= 0.5000\", \"entropy\": \"0.863120568567\", \"samples\": \"14\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"136\", \"rule\": \"diagnosis__73300 <= 0.5000\", \"entropy\": \"0.650022421648\", \"samples\": \"12\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"137\", \"rule\": \"diagnosis__HIERARCHY_8.1.5.4 <= 0.5000\", \"entropy\": \"0.918295834054\", \"samples\": \"3\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"138\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"139\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"                \n",
        "                }              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"140\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"9\", \"value\": \"[ 9.  0.]\"              \n",
        "              }            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"141\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"            \n",
        "            }          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"142\", \"rule\": \"diagnosis__7916 <= 0.5000\", \"entropy\": \"0.439496986922\", \"samples\": \"11\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"143\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"10\", \"value\": \"[  0.  10.]\"            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"144\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"            \n",
        "            }          \n",
        "          }        \n",
        "        }      \n",
        "      },\n",
        "      \"right\": \n",
        "      {\n",
        "        \"id\": \"145\", \"rule\": \"diagnosis__HIERARCHY_7.2.8.2 <= 0.5000\", \"entropy\": \"0.591672778582\", \"samples\": \"7\",\n",
        "        \"left\": \n",
        "        {\n",
        "          \"id\": \"146\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 0.  6.]\"        \n",
        "        },\n",
        "        \"right\": \n",
        "        {\n",
        "          \"id\": \"147\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"        \n",
        "        }      \n",
        "      }    \n",
        "    },\n",
        "    \"right\": \n",
        "    {\n",
        "      \"id\": \"148\", \"rule\": \"diagnosis__28521 <= 0.5000\", \"entropy\": \"0.981940786864\", \"samples\": \"57\",\n",
        "      \"left\": \n",
        "      {\n",
        "        \"id\": \"149\", \"rule\": \"diagnosis__60000 <= 0.5000\", \"entropy\": \"0.956155023684\", \"samples\": \"53\",\n",
        "        \"left\": \n",
        "        {\n",
        "          \"id\": \"150\", \"rule\": \"diagnosis__5856 <= 0.5000\", \"entropy\": \"0.998195879043\", \"samples\": \"40\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"151\", \"rule\": \"diagnosis__HIERARCHY_17.1.7 <= 0.5000\", \"entropy\": \"0.989992791558\", \"samples\": \"34\",\n",
        "            \"left\": \n",
        "            {\n",
        "              \"id\": \"152\", \"rule\": \"diagnosis__V762 <= 0.5000\", \"entropy\": \"0.996316519559\", \"samples\": \"28\",\n",
        "              \"left\": \n",
        "              {\n",
        "                \"id\": \"153\", \"rule\": \"diagnosis__7807 <= 0.5000\", \"entropy\": \"0.954434002925\", \"samples\": \"24\",\n",
        "                \"left\": \n",
        "                {\n",
        "                  \"id\": \"154\", \"rule\": \"diagnosis__HIERARCHY_9.12.2 <= 0.5000\", \"entropy\": \"0.863120568567\", \"samples\": \"21\",\n",
        "                  \"left\": \n",
        "                  {\n",
        "                    \"id\": \"155\", \"rule\": \"diagnosis__HIERARCHY_1.5 <= 0.5000\", \"entropy\": \"0.985228136034\", \"samples\": \"14\",\n",
        "                    \"left\": \n",
        "                    {\n",
        "                      \"id\": \"156\", \"rule\": \"diagnosis__HIERARCHY_7.1 <= 0.5000\", \"entropy\": \"0.845350936622\", \"samples\": \"11\",\n",
        "                      \"left\": \n",
        "                      {\n",
        "                        \"id\": \"157\", \"rule\": \"diagnosis__HIERARCHY_7 <= 0.5000\", \"entropy\": \"0.970950594455\", \"samples\": \"5\",\n",
        "                        \"left\": \n",
        "                        {\n",
        "                          \"id\": \"158\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"2\", \"value\": \"[ 0.  2.]\"                        \n",
        "                        },\n",
        "                        \"right\": \n",
        "                        {\n",
        "                          \"id\": \"159\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 3.  0.]\"                        \n",
        "                        }                      \n",
        "                      },\n",
        "                      \"right\": \n",
        "                      {\n",
        "                        \"id\": \"160\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 0.  6.]\"                      \n",
        "                      }                    \n",
        "                    },\n",
        "                    \"right\": \n",
        "                    {\n",
        "                      \"id\": \"161\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 3.  0.]\"                    \n",
        "                    }                  \n",
        "                  },\n",
        "                  \"right\": \n",
        "                  {\n",
        "                    \"id\": \"162\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"7\", \"value\": \"[ 0.  7.]\"                  \n",
        "                  }                \n",
        "                },\n",
        "                \"right\": \n",
        "                {\n",
        "                  \"id\": \"163\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"3\", \"value\": \"[ 3.  0.]\"                \n",
        "                }              \n",
        "              },\n",
        "              \"right\": \n",
        "              {\n",
        "                \"id\": \"164\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"4\", \"value\": \"[ 4.  0.]\"              \n",
        "              }            \n",
        "            },\n",
        "            \"right\": \n",
        "            {\n",
        "              \"id\": \"165\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 6.  0.]\"            \n",
        "            }          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"166\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"6\", \"value\": \"[ 0.  6.]\"          \n",
        "          }        \n",
        "        },\n",
        "        \"right\": \n",
        "        {\n",
        "          \"id\": \"167\", \"rule\": \"diagnosis__HIERARCHY_8.6.2 <= 0.5000\", \"entropy\": \"0.391243563629\", \"samples\": \"13\",\n",
        "          \"left\": \n",
        "          {\n",
        "            \"id\": \"168\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"12\", \"value\": \"[  0.  12.]\"          \n",
        "          },\n",
        "          \"right\": \n",
        "          {\n",
        "            \"id\": \"169\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"1\", \"value\": \"[ 1.  0.]\"          \n",
        "          }        \n",
        "        }      \n",
        "      },\n",
        "      \"right\": \n",
        "      {\n",
        "        \"id\": \"170\", \"criterion\": \"entropy\", \"impurity\": \"0.0\", \"samples\": \"4\", \"value\": \"[ 4.  0.]\"      \n",
        "      }    \n",
        "    }  \n",
        "  }\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 5
=======
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
>>>>>>> Stashed changes
    }
   ],
   "metadata": {}
  }
 ]
}